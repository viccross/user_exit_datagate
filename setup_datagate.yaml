---
- name: Initialise some things
  hosts: localhost
  gather_facts: true
  tasks:

    - name: Fetch the RHOCP client
      unarchive:
        remote_src: true
        src: https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest-4.14/openshift-client-linux.tar.gz
        dest: /usr/bin
        include: oc
        mode: '755'
      register: result
      retries: 10
      until: "result is not failed"

    - name: Ensure .kube directory exists
      file:
        path: /root/.kube
        state: directory

    - name: Extract kubeconfig from facts
      copy:
        content: "{{ cluster_kubeconfig }}"
        dest: "/root/.kube/config"

    - name: Determine cluster ingress domain
      shell:
        cmd: oc describe ingresscontroller default -n openshift-ingress-operator | grep domain | awk '{print $2;}' | tee {{ playbook_dir }}/cluster_domain.txt
      register: cluster_domain
    
- name: Setup the Data Gate parameters on z/OS
  hosts: zos
  gather_facts: false
  vars:
    PYZ: "/usr/lpp/IBM/cyp/v3r11/pyz"
    ZOAU: "/usr/lpp/IBM/zoautil"
    ansible_python_interpreter: "{{ PYZ }}/bin/python3"
    cluster_domain: "{{ hostvars['localhost']['cluster_domain'] }}"
  environment:
    _BPXK_AUTOCVT: "ON"
    ZOAU_HOME: "{{ ZOAU }}"
    LIBPATH: "{{ ZOAU }}/lib:{{ PYZ }}/lib:/lib:/usr/lib:."
    PATH: "{{ ZOAU }}/bin:{{ PYZ }}/bin:/bin:/var/bin"
    _CEE_RUNOPTS: "FILETAG(AUTOCVT,AUTOTAG) POSIX(ON)"
    _TAG_REDIR_ERR: "txt"
    _TAG_REDIR_IN: "txt"
    _TAG_REDIR_OUT: "txt"
    LANG: "C"
  tasks:

    - name: Set the dg2IPs fact (for use later)
      set_fact:
        dg2IPs: "{{ query('community.general.dig', cluster_domain, qtype='A') }}"
    - name: Allocate the user JCL dataset
      ibm.ibm_zos_core.zos_data_set:
        name: "{{ item }}"
        type: pds
        space_primary: 50
        space_secondary: 15
        space_type: trk
        record_format: fb
        record_length: 80
        block_size: 27920
      loop:
        - IBMUSER.DATAGATE.JCL
        - IBMUSER.DG.HELPER

    - name: Submit the $0DBPARM job
      ibm.ibm_zos_core.zos_job_submit:
        src: files/$0DBPARM.jcl
        location: LOCAL
        wait_time_s: 30
      register: response

    - name: Issue stop command for DBD1
      ibm.ibm_zos_core.zos_operator:
        cmd: "-DBD1 STOP DB2"
        wait_time_s: 90       

    - name: Issue start command for DBD1
      ibm.ibm_zos_core.zos_operator:
        cmd: "-DBD1 START DB2"
        wait_time_s: 10       

    - name: Copy the DATAGATE.JCL jobs
      ibm.ibm_zos_core.zos_copy:
        src: "{{ playbook_dir }}/files/{{ item }}.jcl"
        dest: IBMUSER.DATAGATE.JCL({{ item }})
      loop:
        - $1GENCER
        - $2CPCERT
        - DELETEDA
        - INSERTDA

    - name: Copy the CLEANUP1 job
      ibm.ibm_zos_core.zos_copy:
        src: "{{ playbook_dir }}/files/CLEANUP1.jcl"
        dest: IBMUSER.DG.HELPER(CLEANUP1)

    - name: Copy/replace the DBD1WLMG STC JCL
      ibm.ibm_zos_core.zos_copy:
        src: "{{ playbook_dir }}/files/DBD1WLMG.jcl"
        dest: SYS1.PROCLIB(DBD1WLMG)
        force: true
        force_lock: true
        backup: true
        backup_name: SYS1.PROCLIB(DBD1WLM9)

    - name: Submit the $3CRTTAB job
      ibm.ibm_zos_core.zos_job_submit:
        src: files/$3CRTTAB.jcl
        location: LOCAL
        wait_time_s: 30
      register: response

    - name: Submit the $5STPROC job
      ibm.ibm_zos_core.zos_job_submit:
        src: files/$5STPROC.jcl
        location: LOCAL
        wait_time_s: 30
        max_rc: 4
      register: result

    - name: Submit the $6STPROC job
      ibm.ibm_zos_core.zos_job_submit:
        src: files/$6STPROC.jcl
        location: LOCAL
        wait_time_s: 30
      register: result

    - name: Fetch existing PAGENT config file
      ibm.ibm_zos_core.zos_copy:
        remote_src: true
        src: TCPIP.TCPPARMS(PAGCONF)
        dest: /tmp/ansible.PAGCONF
    
    - name: Get the current ATTLS config file name
      shell:
        cmd: grep -i TTLSConfig /tmp/ansible.PAGCONF | awk '{print $2;}'
      register: pagentfile

    - name: Move the PAGENT config file for OLD FILE (PDS member)
      when: "'TCPIP.TCPPARMS(PAGTTLS)' in pagentfile.stdout"
      block:
      - name: Create the /etc/pagent directory
        file:
          path: /etc/pagent
          state: directory
      - name: Copy PAGTTLS file to zFS
        ibm.ibm_zos_core.zos_copy:
          src: "{{ pagentfile.stdout[3:-1] }}"
          dest: /etc/pagent/pagttls.conf
          remote_src: true
          force: true
      - name: Remove the old file
        ibm.ibm_zos_core.zos_data_set:
          name: "{{ pagentfile.stdout[3:-1] }}"
          type: MEMBER
          state: absent
          force: true

    - name: Update TTLS config file
      ibm.ibm_zos_core.zos_blockinfile:
        src: /etc/pagent/pagttls.conf
        block: "{{ lookup('template', 'files/pagttls.conf.j2') }}"
        insertbefore: EOF
        force: true
        backup: true
        backup_name: /etc/pagent/pagttls.conf.bak

    - name: Modify conflicting TTLS rule
      ibm.ibm_zos_core.zos_lineinfile:
        src: /etc/pagent/pagttls.conf
        regexp: '^.*LocalPortRange.*8101-8102.*$'
        line: '    LocalPortRange 8111-8112'

    - name: Update PAGENT config file
      ibm.ibm_zos_core.zos_lineinfile:
        src: TCPIP.TCPPARMS(PAGCONF)
        regexp: '^TTLSConfig  '
        line: TTLSConfig       /etc/pagent/pagttls.conf
        backup: true
        backup_name: TCPIP.TCPPARMS(PAGCONF9)
        force: true

    - name: Issue refresh command for PAGENT
      ibm.ibm_zos_core.zos_operator:
        cmd: "F PAGENT,REFRESH"
        wait_time_s: 10

    - name: Get the current ATTLS policy
      shell:
        cmd: pasearch -t
      register: result
    - name: Output the result (if it didn't already)
      debug:
        msg: "{{ result.stdout }}"

- name: Stall for a while for CP4D pipeline
  hosts: localhost
  gather_facts: true
  tasks:

    - name: Do a big pause, 1337-style
      block:
        - name: Do a little pause, repeatedly, so that Terraform knows we're still here
          shell: /bin/false
          register: result
          until: 'result.rc == 0'
          retries: 45
          delay: 120
      rescue:
        - name: Save it
          shell: /bin/true

    - name: Create the PVC for Data Gate
      block:
        - name: Apply the YAML
          shell:
            cmd: oc apply -f {{ playbook_dir }}/files/pvc_create.yaml
          register: pvc_result
          until: 'pvc_result is not failed'
          retries: 10
          delay: 30
      rescue:
        - name: Save it, if needed
          shell: /bin/true

    - name: Wait for CP4D, up to two hours
      shell:
        cmd: oc get pipelinerun -n default
      register: result
      retries: 24
      until: '"Completed" in result.stdout'
      delay: 300

    - name: Fetch the secret
      shell:
        cmd: oc get secret platform-auth-idp-credentials -n cpd -ojsonpath='{.data.admin_password}' | base64 -d
      register: cpd_admin_pass

    - name: Run a task to deploy DG instance
      include_tasks:
        file: files/datagate_create.yml
      vars:
        cpd_user: cpadmin
        cpd_password: "{{ cpd_admin_pass.stdout }}"
        pvc_name: datagate-pvc
        instance_name: dg1
        namespace: cpd
        route_port: "443"
        bucket_endpoint: https://s3.{{ cos_region }}.cloud-object-storage.appdomain.cloud
        host_prefix: dg1

    - name: Create the user_exit_text_output.txt file
      copy:
        content: |
          Your Cloud Pak for Data admin console can be found at:
            https://cpd-cpd.{{ lookup('file', 'cluster_domain.txt') }}
          Your admin user ID is:
            cpadmin
          The secret/password to log on is:
            {{ cpd_admin_pass.stdout }}
        dest: user_exit_text_output.txt
